{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4834e2ec-7991-4167-a2aa-d00f19a064be",
   "metadata": {},
   "source": [
    "# Checking Datasets\n",
    "\n",
    "**Author: Shahzad Sanjrani**\n",
    "\n",
    "**Date: 21.11.24**\n",
    "\n",
    "Notebook to just sanity check the input of the h5 input/output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a957779-99e7-47c6-b9a3-55d1c1b2b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import mplhep as hep\n",
    "import awkward as ak\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8936781-a301-4eab-b280-78095c37bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dir = \"/nfs/dust/cms/user/sanjrani/SPANet_Investigations/investigation2/pepper_analysis/output/h4t_systematics/spanet\"\n",
    "\n",
    "# infile = \"input/genstudies_2017_jpt20_GENRECO_training/TTTT_TuneCP5_13TeV-amcatnlo-pythia8/TTTT_TuneCP5_13TeV-amcatnlo-pythia8_even_train.h5\"\n",
    "infile = \"input/genstudies_2017_jpt20_GENRECO_training/TTZprimeToTT_M-500_Width4_TuneCP5_13TeV-madgraph-pythia8/TTZprimeToTT_M-500_Width4_TuneCP5_13TeV-madgraph-pythia8_even_train.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252663ef-9f5c-4b29-a83f-9ea6277bb281",
   "metadata": {},
   "source": [
    "### What do we want to check?\n",
    "\n",
    "Some of the jet distributions.\n",
    "\n",
    "Some of the assignment percentages.\n",
    "\n",
    "Some of the masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e40db46-07c3-4797-b5f9-8367cdfb6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hepfig(figsize=(10,10)):\n",
    "    ''' plt.figure but use the mplhep package to make it look nice '''\n",
    "    hep.style.use(\"CMS\")\n",
    "    mpl.rcParams[\"font.size\"] = 20\n",
    "    plt.figure(figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21e71c18-692e-4db3-bcf8-7e1ad72d2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order_of_mag(min_value, counter_max = 10):\n",
    "    order_of_mag = 1\n",
    "    counter = 0\n",
    "    while order_of_mag > min_value:\n",
    "        order_of_mag = order_of_mag / 10\n",
    "        counter += 1\n",
    "        if counter > counter_max:\n",
    "            break\n",
    "    return order_of_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b1a8202-54c6-4012-b33a-a22a7de3bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ymin(counts, density=False, yscale='linear'):\n",
    "    ymin = 0\n",
    "    if yscale == 'log' or density == True:\n",
    "        ymin = 1\n",
    "        if np.min(counts) < ymin:\n",
    "            ymin = get_order_of_mag(np.min(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fd80ba2-3d8c-49d3-9ca2-660bbfb024d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_input(input_key, input_attribute, file, bins=None, yscale='linear'):\n",
    "\n",
    "    try:\n",
    "        inarray_mask = ak.Array(file[f\"INPUTS/{input_key}/MASK\"])\n",
    "    except:\n",
    "        inarray_mask = None\n",
    "\n",
    "    inarray = ak.Array(file[f\"INPUTS/{input_key}/{input_attribute}\"])\n",
    "    if inarray_mask is not None:\n",
    "        inarray = inarray[inarray_mask]\n",
    "\n",
    "    plot_hepfig()\n",
    "    if bins is None:\n",
    "        # default is printing 10 bins between min and max\n",
    "        bins = np.linspace(np.min(inarray), np.max(inarray), 10)\n",
    "        \n",
    "    counts, _, _ = plt.hist(ak.flatten(inarray), bins=bins, label=f\"{input_key}:{input_attribute}\")\n",
    "    plt.yscale(yscale)\n",
    "    plt.xlim((bins[0],bins[-1]))\n",
    "    plt.ylim((0, np.max(counts)*1.35))\n",
    "    plt.xlabel(f\"N. {input_key}\")\n",
    "    plt.ylabel(f\"{input_attribute}\")\n",
    "\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac53e4c2-e892-48b6-a87a-a97eb7b79e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resonance_checks(resonance_reco, resonance_keys, label=None, save=None, check_name=None, fpath=None):\n",
    "    '''\n",
    "    Plot fraction of events of how many events where N res in res_keys are reconstructed\n",
    "    '''\n",
    "    res_reco = np.array( [resonance_reco[res] for res in resonance_keys] )\n",
    "    res_n = np.sum(res_reco.astype(int), axis=0)\n",
    "    plot_hepfig()\n",
    "\n",
    "    yscale, density, bins = 'linear', True, np.arange(0, len(resonance_keys)+2)\n",
    "    counts, _, _ = plt.hist( res_n, bins=bins, density=density, label=label)\n",
    "    ymin = get_ymin(counts, density=density, yscale=yscale)\n",
    "    plt.ylim((ymin, np.max(counts)*1.35))\n",
    "    plt.xlim((bins[0], bins[-1]))\n",
    "    plt.xlabel(f\"N. reconstructable\")\n",
    "    plt.ylabel(f\"Fraction of events\")\n",
    "    plt.yscale(yscale)\n",
    "    plt.legend()\n",
    "\n",
    "    if save is not None and check_name is not None and fpath is not None:\n",
    "        # save is dir\n",
    "        # check_name is suffix\n",
    "        # fpath is h5 file path\n",
    "        fname = os.path.basename(fpath)\n",
    "        fname = fname.replace(\".h5\", \"\")\n",
    "        savepath = os.path.join(save, f\"{fname}_{check_name}.pdf\")\n",
    "        plt.savefig(savepath)\n",
    "        plt.close()\n",
    "\n",
    "def plot_targets(file, tttt_checks=True, yscale='linear', save=None, fpath=None):\n",
    "    '''\n",
    "    assumes we have the following: (cba to generalise)\n",
    "    - {'ti':['q1','q2','b'], ..} for i in [1,2,3,4]\n",
    "    - {'zpti':['q1','q2','b'], 'nzpti':['q1','q2','b'],..} for i in [1,2]\n",
    "    '''\n",
    "    resonance_keys = {}\n",
    "    for k in list(file[\"TARGETS\"].keys()):\n",
    "        resonance_keys[k] = list(file[f\"TARGETS/{k}\"].keys())\n",
    "\n",
    "    # generalised\n",
    "    resonance_reco = {}\n",
    "    for resonance in resonance_keys:\n",
    "        daughters = np.array([ file[f\"TARGETS/{resonance}/{daughter}\"] for daughter in resonance_keys[resonance] ])\n",
    "        reco = np.all( daughters >= 0, axis = 0)\n",
    "        resonance_reco[resonance] = reco\n",
    "\n",
    "    plot_hepfig()\n",
    "    x_pos, x_labels = np.arange(0,len(list(resonance_reco.keys())))+0.5, list(resonance_reco.keys())\n",
    "    heights = [ np.sum(resonance_reco[k]) for k in resonance_keys ]\n",
    "    \n",
    "    plt.bar(x_pos, heights, width=0.5, tick_label=x_labels)\n",
    "    plt.ylim((0, np.max(heights)*1.35))\n",
    "    plt.xlabel(f\"Top\")\n",
    "    plt.ylabel(f\"N. reconstructable\")\n",
    "\n",
    "    check_name = \"resonance_reco\"\n",
    "    if save is not None and fpath is not None:\n",
    "        fname = os.path.basename(fpath)\n",
    "        fname = fname.replace(\".h5\", \"\") \n",
    "        savepath = os.path.join(save, f\"{fname}_{check_name}.pdf\")\n",
    "        plt.savefig(savepath)\n",
    "        plt.close()\n",
    "\n",
    "    if tttt_checks:\n",
    "\n",
    "        # check how many hnt\n",
    "        tops = ['t1','t2','t3','t4']\n",
    "        resonance_checks(resonance_reco, resonance_keys=tops, label='SM tops', save=save, check_name=\"SM_tops\", fpath=fpath)\n",
    "\n",
    "        # check how many hnt (zp)\n",
    "        tops = ['zpt1','zpt2','nzpt1','nzpt2']\n",
    "        resonance_checks(resonance_reco, resonance_keys=tops, label='Zp, non-Zp tops', save=save, check_name=\"Zp_nZp_tops\", fpath=fpath)\n",
    "\n",
    "        # check how many zp tt\n",
    "        tops = ['zpt1','zpt2']\n",
    "        resonance_checks(resonance_reco, resonance_keys=tops, label='Zp tops', save=save, check_name=\"Zp_tops\", fpath=fpath)\n",
    "\n",
    "        # check how many non z' tt\n",
    "        tops = ['nzpt1','nzpt2']\n",
    "        resonance_checks(resonance_reco, resonance_keys=tops, label='non-Zp tops', save=save, check_name=\"nZp_tops\", fpath=fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ed3700a-08d8-4ae2-b8a7-4eebbb286679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_group(group_four_vectors):\n",
    "    '''\n",
    "    Given dictionary in format : {'pt':[..], 'phi':[..], 'eta':[..], 'mass':[..], 'match':[..]}\n",
    "    - calculate invariant mass\n",
    "    '''\n",
    "    ## -- Initial settings -- ##\n",
    "    # 1. convert to np arrays\n",
    "    for v in group_four_vectors: \n",
    "        group_four_vectors[v] = np.array(group_four_vectors[v])\n",
    "\n",
    "    # 2. check if calculation possible\n",
    "    rep_cartesian = ['px','py','pz','energy']\n",
    "    rep_polar = ['pt','eta','phi','mass']\n",
    "    if not(set(rep_cartesian) < set(list(group_four_vectors.keys()))) and not (set(rep_polar) < set(list(group_four_vectors.keys()))):\n",
    "        raise ValueError(f\"Can't calculate M: both {rep_cartesian} and {rep_polar} not given\")\n",
    "\n",
    "    # 3. check if we need to convert polar -> cartesian\n",
    "    convert = not (set(rep_cartesian) < set(list(group_four_vectors.keys())))\n",
    "    \n",
    "    ## -- Convert to px, py, pz, E --- ##\n",
    "    if convert:\n",
    "        group_four_vectors['px'] = group_four_vectors['pt'] * np.cos(group_four_vectors['phi'])\n",
    "        group_four_vectors['py'] = group_four_vectors['pt'] * np.sin(group_four_vectors['phi'])\n",
    "        group_four_vectors['pz'] = group_four_vectors['pt'] * np.sinh(group_four_vectors['eta'])\n",
    "        group_four_vectors['energy'] = np.sqrt( group_four_vectors['px']**2 + group_four_vectors['py']**2 + group_four_vectors['pz']**2 + group_four_vectors['mass']**2 )\n",
    "    \n",
    "    ## -- Sum the four vectors and get mass -- ##\n",
    "    px = np.sum(group_four_vectors['px'], axis=0)\n",
    "    py = np.sum(group_four_vectors['py'], axis=0)\n",
    "    pz = np.sum(group_four_vectors['pz'], axis=0)\n",
    "    energy = np.sum(group_four_vectors['energy'], axis=0)\n",
    "    mass = np.sqrt( energy**2 - (px**2 + py**2 + pz**2) )\n",
    "    \n",
    "    if 'match' in group_four_vectors: \n",
    "        match = np.all( group_four_vectors['match'], axis=0 )\n",
    "    else:\n",
    "        match = np.full_like(px, True)\n",
    "\n",
    "    return {\"px\":px, \"py\":py, \"pz\":pz, \"energy\":energy, \"mass\":mass, \"match\":match}\n",
    "\n",
    "def plot_mass(mass, match, label, save=None, fpath=None):\n",
    "    '''\n",
    "    Given mass array, match mask array --> plot it\n",
    "    '''\n",
    "    plot_hepfig()\n",
    "    bins = np.arange(0, 5000, 50) \n",
    "    counts, _, _ = plt.hist(mass[match], bins=bins, label=label)\n",
    "    plt.xlabel(f\"Mass [GeV]\")\n",
    "    plt.ylabel(f\"N. particles\")\n",
    "    plt.xlim((bins[0],bins[-1]))\n",
    "    plt.ylim((0,1.35*np.max(counts)))\n",
    "    plt.legend()\n",
    "\n",
    "    if save is not None and fpath is not None:\n",
    "        fname = os.path.basename(fpath)\n",
    "        fname = fname.replace(\".h5\", \"\") \n",
    "        savepath = os.path.join(save, f\"{fname}_{label}.pdf\")\n",
    "        plt.savefig(savepath)\n",
    "        plt.close()\n",
    "\n",
    "def resonance_invariant_mass(file, input_2_target, targets_set=None, save=None, fpath=None):\n",
    "    '''\n",
    "    calculate invariant mass of resonance particles:\n",
    "    - input_2_target = dict in format {'res_i':'input_group_a', ..}\n",
    "    - targets_set = (optional) dict in format {'big_res_x':['res_i','res_j'], 'big_res_y':[...]}\n",
    "    '''\n",
    "    \n",
    "    ## -- Initial settings -- ##\n",
    "    rep_cartesian = ['px','py','pz','energy']\n",
    "    rep_polar = ['pt','eta','phi','mass']\n",
    "    \n",
    "    resonance_four_vectors_all = {}\n",
    "\n",
    "    for resonance, resonance_input in input_2_target.items():\n",
    "        input_components = list(file[f\"INPUTS/{resonance_input}\"].keys())\n",
    "\n",
    "        # -- check if possible -- #\n",
    "        if set(rep_cartesian) < set(input_components):\n",
    "            four_vectors = rep_cartesian\n",
    "        elif set(rep_polar) < set(input_components):\n",
    "            four_vectors = rep_polar\n",
    "        else:\n",
    "            print(f\"Cannot calculate {resonance} with input {resonance_input}\")\n",
    "            continue\n",
    "            \n",
    "        # -- get four vectors from resonance -- #\n",
    "        daughters = list(file[f\"TARGETS/{resonance}\"].keys())\n",
    "        daughters_four_vectors = { component: [] for component in four_vectors }\n",
    "        \n",
    "        for component in daughters_four_vectors:\n",
    "            for daughter in daughters:\n",
    "                \n",
    "                input_component = np.array(file[f\"INPUTS/{resonance_input}/{component}\"])\n",
    "                daughter_labels = np.array(file[f\"TARGETS/{resonance}/{daughter}\"])\n",
    "                \n",
    "                input_component_d = input_component[ np.arange(input_component.shape[0]), daughter_labels ] # e.g., get jet.pt's for that daughter\n",
    "                daughters_four_vectors[component].append(input_component_d)\n",
    "\n",
    "        daughters_four_vectors['match'] = [ np.array(file[f\"TARGETS/{resonance}/{daughter}\"]) > -1  for daughter in daughters ]\n",
    "\n",
    "        # get 4vec (cartesian) dict from daughters for resonance\n",
    "        resonance_four_vectors = combine_group(daughters_four_vectors)\n",
    "\n",
    "        ## -- add to collection of resonances -- ##\n",
    "        resonance_four_vectors_all[resonance] = resonance_four_vectors\n",
    "\n",
    "        ## -- plot -- ##\n",
    "        plot_mass(resonance_four_vectors['mass'], resonance_four_vectors['match'], resonance, save=save, fpath=fpath)\n",
    "\n",
    "    ## -- Repeat above for groups of resonances -- ##\n",
    "    if targets_set is not None:\n",
    "        \n",
    "        four_vectors = rep_cartesian # assumed because of combine_group output\n",
    "        \n",
    "        for bigres, bigres_group in targets_set.items():\n",
    "            \n",
    "            bigres_group_4vecs = { component:[] for component in four_vectors }\n",
    "            for component in bigres_group_4vecs:\n",
    "                for res in bigres_group:\n",
    "                    bigres_group_4vecs[component].append( resonance_four_vectors_all[res][component] )\n",
    "            bigres_group_4vecs['match'] = [ resonance_four_vectors_all[res]['match'] for res in bigres_group ]\n",
    "\n",
    "            bigres_4vecs = combine_group(bigres_group_4vecs)\n",
    "\n",
    "            plot_mass(bigres_4vecs['mass'], bigres_4vecs['match'], bigres, save=save, fpath=fpath)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d3dfec-46a4-4d42-9916-35ded9000cb8",
   "metadata": {},
   "source": [
    "## Make your checks here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e823055c-a6b7-42b1-9beb-60f42757295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_path = os.path.join(store_dir, infile) # full path\n",
    "save_dir = os.path.join(os.path.dirname(infile_path), \"plots\") # where to save plots\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "with h5py.File(infile_path, \"r\") as file:\n",
    "\n",
    "    # plot_input(\"Jets\", \"pt\", file)\n",
    "    # plot_targets(file, tttt_checks=True, save=save_dir, fpath=infile_path)\n",
    "\n",
    "    # some manual work involved\n",
    "    input_2_target = { res:'Jets' for res in ['t1','t2','t3','t4','zpt1','zpt2','nzpt1','nzpt2'] }\n",
    "    targets_set = {'Zp':['zpt1','zpt2'], 'nZp':['nzpt1','nzpt2']}\n",
    "    resonance_invariant_mass(file, input_2_target, targets_set=targets_set, save=save_dir, fpath=infile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e4f8c3-52a8-4d08-b60b-3a45584676fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57240167-8bdd-458c-b137-9fa81cffb739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "runSPANet",
   "language": "python",
   "name": "runspanet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
