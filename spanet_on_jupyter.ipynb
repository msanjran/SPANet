{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760c3509-22ee-4977-8278-a04d5c0deab0",
   "metadata": {},
   "source": [
    "# SPA-Net on Jupyter Notebooks\n",
    "\n",
    "**Author: Shahzad Sanjrani**\n",
    "\n",
    "**Date: 21.11.24**\n",
    "\n",
    "This notebook is about seeing if it is, in principle, possible to run SPA-Net on a jupyter notebook. Whether it's efficient is another story (can always ask for a GPU node right?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e9750d-aea6-471b-a302-a5a490c1223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spanet\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c479f12c-1ad4-4e7a-9014-1a2911021ff8",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Essentially copying train.py into jupyter because we want to see what's up...\n",
    "\n",
    "1. Initialise variables\n",
    "2. Import extra modules\n",
    "3. Training script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc0b3c-fb78-43f7-8aef-4da21f908f5d",
   "metadata": {},
   "source": [
    "### Initial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f4ac2a-acd0-46ca-bd32-3bceccabf5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dir = \"/nfs/dust/cms/user/sanjrani/SPANet_Investigations/investigation2/pepper_analysis/output/h4t_systematics/spanet/input\"\n",
    "sample_dir = \"genstudies_2017_jpt20_GENRECO_training/TTZprimeToTT_M-500_Width4_TuneCP5_13TeV-madgraph-pythia8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b476b0cd-2010-43d1-8c71-c68f10821478",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- WHO, WHAT, HOW ARE WE TRAINING --- ###\n",
    "event_file = \"./event_files/round2/full_hadronic_tttt_reco_tops.yaml\"\n",
    "options_file = \"./options_files/round2/reco_four_tops/full_hadronic_tttt_reconstruct_1.json\"\n",
    "training_file = os.path.join(store_dir, sample_dir, \"TTZprimeToTT_M-500_Width4_TuneCP5_13TeV-madgraph-pythia8_even_train.h5\")\n",
    "validation_file = os.path.join(store_dir, sample_dir, \"TTZprimeToTT_M-500_Width4_TuneCP5_13TeV-madgraph-pythia8_even_val.h5\")\n",
    "gpus = 0\n",
    "epochs = 30\n",
    "batch_size = 512\n",
    "\n",
    "### -- WHERE TO PUT OUTPUT --- ###\n",
    "log_dir = \"/nfs/dust/cms/user/sanjrani/SPANet_Investigations/investigation2/pepper_analysis/output/h4t_systematics/spanet/models\"\n",
    "name = \"spanet_output\"\n",
    "\n",
    "### --- EXTRAS (IGNORE) --- ###\n",
    "checkpoint = None # load from a training state\n",
    "state_dict = None # load from checkpoing by only model weights\n",
    "freeze_state_dict = False # freeze weights loaded from state_dict (for finetuning new layers)\n",
    "\n",
    "torch_script = False # compile using torch_script\n",
    "fp16 = False # use torch AMP for training\n",
    "verbose = False\n",
    "full_events = False\n",
    "profile = False # profile network for single training epoch\n",
    "time_limit = None\n",
    "limit_dataset = None\n",
    "random_seed = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf02262-00d5-4abe-83ff-25c69d138091",
   "metadata": {},
   "source": [
    "### Load in extra modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a631b32-cdea-4555-a061-cd7c54b5b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from typing import Optional\n",
    "from os import getcwd, makedirs, environ\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.profilers import PyTorchProfiler\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.progress.rich_progress import _RICH_AVAILABLE\n",
    "from pytorch_lightning.loggers.wandb import _WANDB_AVAILABLE, WandbLogger\n",
    "\n",
    "from pytorch_lightning.callbacks import (\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    RichProgressBar,\n",
    "    RichModelSummary,\n",
    "    DeviceStatsMonitor,\n",
    "    ModelSummary,\n",
    "    TQDMProgressBar\n",
    ")\n",
    "\n",
    "from spanet import JetReconstructionModel, Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd0cf58-5322-4427-aa66-f70cb77733a1",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1b4cd-e6a9-4d7e-8867-88cbf958f9de",
   "metadata": {},
   "source": [
    "#### Setup the situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5dbf9cf-b11c-4a0f-838b-16ce950e6e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0/29</span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">25/86</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:02:39 • 0:06:05</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">0.17it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">v_num: 1 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mEpoch 0/29\u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━\u001b[0m\u001b[38;2;98;6;224m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m25/86\u001b[0m \u001b[38;5;245m0:02:39 • 0:06:05\u001b[0m \u001b[38;5;249m0.17it/s\u001b[0m \u001b[37mv_num: 1 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/nfs/dust/cms/user/sanjrani/Computing/Environment/miniconda3/envs/spanet-118/lib/python3.10/site-packages/pytorch_l\n",
       "ightning/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
       "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/nfs/dust/cms/user/sanjrani/Computing/Environment/miniconda3/envs/spanet-118/lib/python3.10/site-packages/pytorch_l\n",
       "ightning/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
       "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Whether or not this script version is the master run or a worker\n",
    "master = True\n",
    "if \"NODE_RANK\" in environ:\n",
    "    master = False\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "# Create options file and load any optional extra information.\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "options = Options(event_file, training_file, validation_file)\n",
    "\n",
    "if options_file is not None:\n",
    "    with open(options_file, 'r') as json_file:\n",
    "        options.update_options(json.load(json_file))\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "# Command line overrides for common option values.\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "options.verbose_output = verbose\n",
    "if master and verbose:\n",
    "    print(f\"Verbose output activated.\")\n",
    "\n",
    "if full_events:\n",
    "    if master:\n",
    "        print(f\"Overriding: Only using full events\")\n",
    "    options.partial_events = False\n",
    "    options.balance_particles = False\n",
    "\n",
    "if gpus is not None:\n",
    "    if master:\n",
    "        print(f\"Overriding GPU count: {gpus}\")\n",
    "    options.num_gpu = gpus\n",
    "\n",
    "if batch_size is not None:\n",
    "    if master:\n",
    "        print(f\"Overriding Batch Size: {batch_size}\")\n",
    "    options.batch_size = batch_size\n",
    "\n",
    "if limit_dataset is not None:\n",
    "    if master:\n",
    "        print(f\"Overriding Dataset Limit: {limit_dataset}%\")\n",
    "    options.dataset_limit = limit_dataset / 100\n",
    "\n",
    "if epochs is not None:\n",
    "    if master:\n",
    "        print(f\"Overriding Number of Epochs: {epochs}\")\n",
    "    options.epochs = epochs\n",
    "\n",
    "if random_seed > 0:\n",
    "    options.dataset_randomization = random_seed\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "# Print the full hyperparameter list\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "if master:\n",
    "    options.display()\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "# Begin the training loop\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create the initial model on the CPU\n",
    "model = JetReconstructionModel(options, torch_script)\n",
    "\n",
    "if state_dict is not None:\n",
    "    if master:\n",
    "        print(f\"Loading state dict from: {state_dict}\")\n",
    "\n",
    "    state_dict = torch.load(state_dict, map_location=\"cpu\")[\"state_dict\"]\n",
    "    missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    if master:\n",
    "        print(f\"Missing Keys: {missing_keys}\")\n",
    "        print(f\"Unexpected Keys: {unexpected_keys}\")\n",
    "\n",
    "    if freeze_state_dict:\n",
    "        for pname, parameter in model.named_parameters():\n",
    "            if pname in state_dict:\n",
    "                parameter.requires_grad_(False)\n",
    "\n",
    "# Construct the logger for this training run. Logs will be saved in {logdir}/{name}/version_i\n",
    "log_dir = getcwd() if log_dir is None else log_dir\n",
    "logger = TensorBoardLogger(save_dir=log_dir, name=name)\n",
    "# logger = (\n",
    "#     WandbLogger(name=name, save_dir=log_dir)\n",
    "#     if _WANDB_AVAILABLE else\n",
    "#     TensorBoardLogger(save_dir=log_dir, name=name)\n",
    "# )\n",
    "\n",
    "# Create the checkpoint for this training run. We will save the best validation networks based on 'accuracy'\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        verbose=options.verbose_output,\n",
    "        monitor='validation_accuracy',\n",
    "        save_top_k=3,\n",
    "        mode='max',\n",
    "        save_last=True\n",
    "    ),\n",
    "    LearningRateMonitor(),\n",
    "    DeviceStatsMonitor(),\n",
    "    RichProgressBar() if _RICH_AVAILABLE else TQDMProgressBar(),\n",
    "    RichModelSummary(max_depth=1) if _RICH_AVAILABLE else ModelSummary(max_depth=1)\n",
    "]\n",
    "\n",
    "epochs = options.epochs\n",
    "profiler = None\n",
    "if profile:\n",
    "    epochs = 1\n",
    "    profiler = PyTorchProfiler(emit_nvtx=True)\n",
    "\n",
    "# Create the final pytorch-lightning manager\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\" if options.num_gpu > 0 else \"auto\",\n",
    "    devices=options.num_gpu if options.num_gpu > 0 else \"auto\",\n",
    "    strategy=\"ddp\" if options.num_gpu > 1 else \"auto\",\n",
    "    precision=\"16-mixed\" if fp16 else \"32-true\",\n",
    "\n",
    "    gradient_clip_val=options.gradient_clip if options.gradient_clip > 0 else None,\n",
    "    max_epochs=epochs,\n",
    "    max_time=time_limit,\n",
    "\n",
    "    logger=logger,\n",
    "    profiler=profiler,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save the current hyperparameters to a json file in the checkpoint directory\n",
    "if master:\n",
    "    print(f\"Training Version {trainer.logger.version}\")\n",
    "    makedirs(trainer.logger.log_dir, exist_ok=True)\n",
    "\n",
    "    with open(f\"{trainer.logger.log_dir}/options.json\", 'w') as json_file:\n",
    "        json.dump(options.__dict__, json_file, indent=4)\n",
    "\n",
    "    shutil.copy2(options.event_info_file, f\"{trainer.logger.log_dir}/event.yaml\")\n",
    "\n",
    "trainer.fit(model, ckpt_path=checkpoint)\n",
    "# -------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b24ae-de08-4dc3-9ce6-12288d9ef09d",
   "metadata": {},
   "source": [
    "### Verdict?\n",
    "\n",
    "**Training** on SPA-Net works in jupyter. Is this useful? Not entirely sure, since we want to explore as much as possible and it takes forever to run through these. I think we'll keep training to NAF except for small testing here and there..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17bb389-5f67-47c2-a686-b3c84b7ddb5e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "runSPANet",
   "language": "python",
   "name": "runspanet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
